# üì± API de Traducci√≥n Optimizada para M√≥viles

Servidor de traducci√≥n ultra-ligero usando PyTorch optimizado, dise√±ado para aplicaciones m√≥viles.

## üöÄ Caracter√≠sticas

- ‚úÖ Modelo MarianMT (ingl√©s ‚Üí espa√±ol) optimizado
- ‚úÖ API REST ligera con FastAPI
- ‚úÖ Optimizado para baja latencia (2 threads, num_beams=2)
- ‚úÖ Docker containerizado (~800 MB)
- ‚úÖ CORS habilitado para m√≥viles
- ‚úÖ Procesamiento por lotes eficiente

## üì¶ Instalaci√≥n

### Opci√≥n R√°pida: Usar el servidor simple (Recomendado)

```powershell
# Instalar dependencias
pip install -r requirements-simple.txt

# Iniciar servidor
uvicorn app_simple:app --host 0.0.0.0 --port 8000
```

### Con Docker (Recomendado para producci√≥n)

```powershell
# Construir imagen
docker build -f Dockerfile.simple -t translation-api .

# Ejecutar contenedor
docker run -d -p 8000:8000 translation-api

# O con docker-compose
docker-compose up -d
```

## üîå Uso de la API

### Endpoint principal: Traducir texto

```bash
POST http://localhost:8000/translate
Content-Type: application/json

{
  "text": "Hello, how are you?",
  "max_length": 512
}
```

Respuesta:
```json
{
  "translated_text": "Hola, ¬øc√≥mo est√°s?",
  "source_language": "en",
  "target_language": "es"
}
```

### Traducci√≥n por lotes

```bash
POST http://localhost:8000/translate/batch?max_length=512
Content-Type: application/json

["Hello world", "Good morning", "Thank you"]
```

### Health check

```bash
GET http://localhost:8000/health
```

### Documentaci√≥n interactiva

Una vez iniciado el servidor, visita:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## üì± Integraci√≥n con m√≥viles

### Android (Kotlin/Java)

```kotlin
import okhttp3.*
import org.json.JSONObject

val client = OkHttpClient()
val url = "http://YOUR_SERVER:8000/translate"

val json = JSONObject().apply {
    put("text", "Hello world")
    put("max_length", 512)
}

val body = RequestBody.create(
    MediaType.parse("application/json"),
    json.toString()
)

val request = Request.Builder()
    .url(url)
    .post(body)
    .build()

client.newCall(request).enqueue(object : Callback {
    override fun onResponse(call: Call, response: Response) {
        val result = JSONObject(response.body()?.string())
        val translation = result.getString("translated_text")
        // Usar traducci√≥n
    }
})
```

### iOS (Swift)

```swift
import Foundation

struct TranslationRequest: Codable {
    let text: String
    let max_length: Int
}

struct TranslationResponse: Codable {
    let translated_text: String
    let source_language: String
    let target_language: String
}

func translate(text: String) async throws -> String {
    let url = URL(string: "http://YOUR_SERVER:8000/translate")!
    var request = URLRequest(url: url)
    request.httpMethod = "POST"
    request.setValue("application/json", forHTTPHeaderField: "Content-Type")
    
    let body = TranslationRequest(text: text, max_length: 512)
    request.httpBody = try JSONEncoder().encode(body)
    
    let (data, _) = try await URLSession.shared.data(for: request)
    let response = try JSONDecoder().decode(TranslationResponse.self, from: data)
    
    return response.translated_text
}
```

### React Native / Flutter

```javascript
// React Native
async function translate(text) {
  const response = await fetch('http://YOUR_SERVER:8000/translate', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      text: text,
      max_length: 512
    })
  });
  
  const result = await response.json();
  return result.translated_text;
}
```

## üéØ Optimizaciones para Producci√≥n

### 1. Hosting en la nube

**Railway.app** (gratuito para empezar):
```powershell
# Instalar Railway CLI
npm i -g @railway/cli

# Desplegar
railway login
railway init
railway up
```

**Fly.io** (muy ligero):
```powershell
# Instalar Fly CLI
powershell -Command "iwr https://fly.io/install.ps1 -useb | iex"

# Desplegar
fly launch
fly deploy
```

**Render.com** (f√°cil):
- Conecta tu repositorio Git
- Selecciona "Docker"
- Despliega autom√°ticamente

### 2. Optimizaciones adicionales

```python
# En app.py, puedes agregar cach√©:
from functools import lru_cache

@lru_cache(maxsize=1000)
def translate_text_cached(text: str, max_length: int = 512):
    return translate_text(text, max_length)
```

### 3. Reducir latencia

- Usar modelos cuantizados (`use_quantized=True`)
- Limitar `max_length` seg√∫n tus necesidades
- Usar un CDN/proxy cerca de tus usuarios
- Implementar cach√© de traducciones comunes

## üìä Tama√±os aproximados

- Modelo original (safetensors): ~300 MB
- Docker image: ~800 MB
- Memoria RAM en ejecuci√≥n: ~500-700 MB
- Latencia promedio: 100-300ms por oraci√≥n

## üéØ Optimizaciones Implementadas

1. **Reducci√≥n de beams**: `num_beams=2` (vs 4) para 2x m√°s r√°pido
2. **Threads limitados**: `torch.set_num_threads(2)` para m√≥viles
3. **Greedy decoding**: `do_sample=False` para mayor velocidad
4. **Max length reducido**: 128 tokens por defecto (ajustable)
5. **Procesamiento por lotes**: endpoint `/translate/batch` optimizado

## üîß Troubleshooting

### No encuentra el modelo
Aseg√∫rate de estar en el directorio `endpoint` y que los archivos del modelo est√©n presentes:
```powershell
ls config.json, model.safetensors, tokenizer_config.json
```

### Memoria insuficiente
Reduce `max_length` en las peticiones o ajusta `num_beams=1` en `app_simple.py`

### Error en m√≥viles: CORS
El servidor ya tiene CORS habilitado. Si a√∫n tienes problemas, verifica que est√©s usando la URL correcta (no `localhost` desde m√≥vil, usa la IP de tu servidor).

## üìù Licencia

Este proyecto usa el modelo MarianMT de Hugging Face, sujeto a sus licencias respectivas.

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Abre un issue o pull request.

---

**¬øNecesitas ayuda?** Abre un issue en el repositorio.
